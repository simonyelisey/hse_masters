{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "ohmVvPQgKj58"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPR4N-wiEvE"
      },
      "source": [
        "В этом задании две части - теоретическая и практическая. Теорию можно набирать в латехе или просто решить на листочке, сфотографировать и отправить вместе с заполненным ноутбуком в anytask.\n",
        "\n",
        "Максимальный балл за задание - 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMZ5My7kiPY_"
      },
      "source": [
        "# Часть 1 (теоретическая).\n",
        "\n",
        "## Задание 1 (**1.5 балла**).\n",
        "\n",
        "Пусть $f(X)=ln(detX), X\\in\\mathbb{R}^{n\\times n}$. Найдите производную $\\nabla_X f(X).$\n",
        "\n",
        "Для решения воспользуемся правилом дифференцирования сложной функции и таблицой стандартных производных для дифференцирования $detX$ [Матрично-векторное дифференцирование](http://www.machinelearning.ru/wiki/images/5/50/MOMO17_Seminar2.pdf):\n",
        "\n",
        "**Решение**:\n",
        "\n",
        "\n",
        "$\\nabla_X f(X) = \\frac{d}{dX}(ln(detX)) = \\frac{d}{dX}(ln(detX)) * \\frac{d}{dx}(detX) = \\frac{1}{detX} * detX*X^{-T} = X^{-T}.$\n",
        "\n",
        "## Задание 2 (**2 балла**).\n",
        "\n",
        "Пусть $f(x)=x^Texp(xx^T)x, x\\in\\mathbb{R}^n,$ а $exp(B)$ - матричная экспонента, $B\\in\\mathbb{R}^{n\\times n}.$ Матричной экспонентой обозначают ряд\n",
        "\n",
        "$I_n+\\frac{B}{1!}+\\frac{B^2}{2!}+\\dots=\\sum\\limits_{k=0}^{\\infty}\\frac{B^k}{k!}.$\n",
        "\n",
        "Найдите производную $\\nabla_x f(x).$\n",
        "\n",
        "**Решение**:\n",
        "\n",
        "$f(x) = x^Texp(xx^T)x = x^T\\sum_{k=0}^\\infty\\frac{(xx^T)^k}{k!}x = \\sum_{k=0}^\\infty\\frac{x^T(xx^T)^kx}{k!} = \\sum_{k=0}^\\infty\\frac{(x^Tx)^{k+1}}{k!}$\n",
        "\n",
        "$\\nabla_x f(x) = \\frac{d}{dx}f(x) = \\frac{d}{dx^Tx} \\sum_{k=0}^\\infty\\frac{(x^Tx)^{k+1}}{k!} *\\frac{d}{dx}(x^Tx) = \\sum_{k=0}^\\infty\\frac{(k + 1)}{k!}(x^Tx)^k 2x = (k+1)exp(x^Tx)2x$\n",
        "\n",
        "## Задание 3 (**1.5 балла**).\n",
        "\n",
        "В случае одномерной Ridge-регрессии минимизируется функция со штрафом:\n",
        "$Q(w) = (y-xw)^T(y-xw)+\\lambda w^2,$\n",
        "где $\\lambda$ - положительный параметр, штрафующий функцию за слишком большие значения $w$.\n",
        "\n",
        "1)  (**0.5 балла**) Найдите производную $\\nabla_w Q(w)$, выведите формулу для оптимального $w$.\n",
        "\n",
        "2) (**0.5 балла**) Найдите вторую производную $\\nabla^2_w Q(w)$. Убедитесь, что мы оказались в точке минимума.\n",
        "\n",
        "3) (**0.5 балла**) Выпишите шаг градиентного спуска в матричном виде.\n",
        "\n",
        "**Решение:**\n",
        "\n",
        "**1)** Найдем 1-ю производную:\n",
        "\n",
        "$\\nabla_w Q = \\frac{d}{dw} (y^Ty - y^Txw - x^Tw^Ty + x^Tw^Txw) + \\frac{d}{dw}(\\lambda w^2) =$\n",
        "\n",
        "$= -xy^T-x^Ty+2x^Txw + 2\\lambda w = -2x^Ty + 2x^Txw + 2\\lambda w $\n",
        "\n",
        "Выведем $w$:\n",
        "\n",
        "$-2x^Ty + 2x^Txw + 2\\lambda w = 0$\n",
        "\n",
        "Перенесем $-2x^Ty$ \n",
        "\n",
        "$2x^Txw + 2\\lambda w = 2x^Ty$\n",
        "\n",
        "Сократим все на 2\n",
        "\n",
        "$x^Txw + \\lambda w = x^Ty$\n",
        "\n",
        "Вынесем $w$ за скобку, и чтобы можно было складывать $x^Tx$ и $\\lambda$, умножим $\\lambda$ на единичную матрицу\n",
        "\n",
        "$(x^Tx +\\lambda E)w = x^Ty$\n",
        "\n",
        "Дальше переносим выражение в скобках и выражаем $w$\n",
        "\n",
        "$w = (x^Tx+\\lambda E)^{-1}x^Ty$\n",
        "\n",
        "**2)** Найдем 2-ю производную:\n",
        "\n",
        "$\\nabla_w^2 Q = \\frac{d}{dw}(-2x^Ty + 2x^Txw + 2\\lambda w) = 2x^Tx +2\\lambda E = x^Tx +\\lambda E$ - здесь также умножили $\\lambda$ на единичную матрицу, чтобы ее можно было складывать с $x^Tx$.\n",
        "\n",
        "Убедимся, что мы в точке минимума:\n",
        "\n",
        "$x^Tx = ||x||^2 >= 0$, причем нулю равно только когда $x = 0$\n",
        "\n",
        "$=> x^Tx +\\lambda E$ - положительно определена, что говорит о том, что мы оказались в точке минимума. [ml handbook, примеры вычисления второй производной](https://ml-handbook.ru/chapters/matrix_diff/intro#%D0%B2%D1%82%D0%BE%D1%80%D0%B0%D1%8F-%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm6_Ln0GoliG"
      },
      "source": [
        "## Часть 2 (практическая).\n",
        "\n",
        "## Задание 4 (**1 балл**).\n",
        "Напишите функцию, вычисляющую значение весов в линейной регрессии по точной (аналитически найденной) формуле."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpY5ETA1AAV7"
      },
      "source": [
        "Аналитическая формула для нахождения весов:\n",
        "\n",
        "$w = (X^TX)^{-1}X^Ty$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "ZrVvpU9miOga"
      },
      "outputs": [],
      "source": [
        "def ols_solution(X, y):\n",
        "    \"\"\"\n",
        "    Аналитическое решение\n",
        "    \"\"\"\n",
        "    \n",
        "    w = np.linalg.inv((X.T @ X)) @ X.T @ y\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shCsTQ1pVcU"
      },
      "source": [
        "## Задание 5 (**1 балл**).\n",
        "Модифицируйте метод градиентного спуска с семинара так, чтобы это теперь был метод стохастического градиентного спуска."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "fTZWxz1zpb9R"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(X, y, learning_rate, iterations):\n",
        "    # добавляем столбец из единиц\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    # случайные веса\n",
        "    params = np.random.rand(X.shape[1])\n",
        "    # массив для лоссов \n",
        "    cost_track = np.zeros((iterations, 1))\n",
        "    for i in range(iterations):\n",
        "      # рандомное наблюдение\n",
        "      random_idx = np.random.randint(len(X - 1))\n",
        "      x = X[random_idx]\n",
        "      y_current = y[random_idx]\n",
        "      # обновление весов\n",
        "      error = x @ params - y_current\n",
        "      params = params - learning_rate * (x * error)\n",
        "      # добавляем лосс в список\n",
        "      cost_track[i] = compute_cost(X, y, params)\n",
        "    \n",
        "    return cost_track, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnRlUa9Npi9o"
      },
      "source": [
        "## Задание 6 (**3 балла**).\n",
        "* **(0 баллов)**. Скопируйте метод градиентного спуска из семинара в этот ноутбук.\n",
        "\n",
        "* **(0.5 балла)**. Обучите линейную регрессию тремя методами (по точной формуле, с помощью GD и с помощью SGD) на данных для задачи регрессии (см. код). Для GD и SGD используйте learning_rate = 0.01, iterations=10000.\n",
        "\n",
        "* **(0.5 балла)**. С помощью каждого метода сделайте предсказание (на всех данных), вычислите качество предсказания r2 (from sklearn.metrics import r2_score). Для получения предсказания можете использовать функцию predict с семинара.\n",
        "\n",
        "\n",
        "Ответьте на следующие вопросы (каждый вопрос - **0.5 балла**): \n",
        "\n",
        "1) все ли методы справились с нахождением минимума? если нет, то почему какой-то из методов не справился?\n",
        "\n",
        "2) сравните время работы методов (используйте библиотеку time): замеряйте время работы соответствующей написанной вами функции.\n",
        "\n",
        "3) для методов GD и SGD нарисуйте графики (для каждого свой) зависимости ошибки (loss) от номера итерации. \n",
        "\n",
        "4) какой метод успешнее всего справился с задачей? (т.е. r2 наибольший)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "ntjWWlXxThv3"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    params = np.random.rand(X.shape[1])\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    cost_track = np.zeros((iterations,1))\n",
        "\n",
        "    for i in range(iterations):\n",
        "        params = params - 2./m * learning_rate * (X.T @ ((X @ params) - y))\n",
        "        cost_track[i] = compute_cost(X, y, params)\n",
        "\n",
        "    return cost_track, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "GZcqsWx8X2ru"
      },
      "outputs": [],
      "source": [
        "def predict(X, params):\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    return X @ params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "kns7FERvTuHg"
      },
      "outputs": [],
      "source": [
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "\n",
        "    cost = (1./m) * (np.linalg.norm(X @ theta - y) ** 2)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "LBu41KSpqbbI"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X, y, _ = make_regression(n_samples=100000, # number of samples\n",
        "                          n_features=10, # number of features\n",
        "                          n_informative=8, # number of useful features \n",
        "                          noise=100, # bias and standard deviation of the guassian noise\n",
        "                          coef=True, # true coefficient used to generated the data\n",
        "                          random_state=123) \n",
        "\n",
        "X = pd.DataFrame(data=X, columns=np.arange(0, X.shape[1]))\n",
        "X[10] = X[6] + X[7] + np.random.random()*0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NefmzPHZ7whE"
      },
      "source": [
        "### Аналитический метод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UVb98lf7ngQ",
        "outputId": "20f4e71d-bf62-4513-d01b-1eec167ab628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "При аналитическом решении r2 = 0.7554626185750483\n",
            "\n",
            "CPU times: user 55.5 ms, sys: 25.9 ms, total: 81.5 ms\n",
            "Wall time: 53.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "ols_weights = ols_solution(X, y)\n",
        "\n",
        "ols_prediction = X @ ols_weights\n",
        "\n",
        "ols_metric = r2_score(y, ols_prediction)\n",
        "\n",
        "print(f'При аналитическом решении r2 = {ols_metric}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4MaBNUm8oO5"
      },
      "source": [
        "### GD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNOMbQ-XBSMd",
        "outputId": "a6d09fcc-b341-44a1-ab0d-48383673284c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.2 s, sys: 6.45 s, total: 32.7 s\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "gd_track, gd_weights = gradient_descent(X, y, 0.01, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QNcdKWM8mAh",
        "outputId": "0edbe96d-6488-4640-9590-54e2dff8199c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "При классическом градиентном спуске r2 = 0.7554626185750483\n"
          ]
        }
      ],
      "source": [
        "gd_prediction = predict(X, gd_weights)\n",
        "\n",
        "gd_metric = r2_score(y, gd_prediction)\n",
        "\n",
        "print(f'При классическом градиентном спуске r2 = {gd_metric}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Oru14pzS94dx",
        "outputId": "a260435c-61bf-424a-fe42-433d130f47fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(gd_track)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhp5tiXa9JYb"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq8sZuwwBOhl",
        "outputId": "9c5f9941-be5e-4978-c04b-46db0414062f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 47.5 s, sys: 26.2 s, total: 1min 13s\n",
            "Wall time: 40.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "sgd_track, sgd_weights = stochastic_gradient_descent(X, y, 0.01, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vtuTSMB9V_p",
        "outputId": "3a249112-afe1-4384-bdcd-706a0997b093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "При классическом градиентном спуске r2 = 0.7311661487685339\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sgd_prediction = predict(X, sgd_weights)\n",
        "\n",
        "sgd_metric = r2_score(y, sgd_prediction)\n",
        "\n",
        "print(f'При классическом градиентном спуске r2 = {sgd_metric}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8V7s2ZRR-CWB",
        "outputId": "52a16f14-dd95-44ea-a99e-d7634766ea35"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(sgd_track)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOTiM_ed_FbV"
      },
      "source": [
        "### Ответы на вопросы:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9RcZ-OC-0n2"
      },
      "source": [
        "1) С нахождением минунима не справился **стохастический градиентный спуск**, так как на каждой итерации он считает градиент на рандомном объекте, поэтому у нас нет гарантии, что на последней итерации, ему попадется объект, градиент которого ведет в минимум.\n",
        "\n",
        "2) Стохастический градиентный спуск работает медленнее всех, что очень странно, видимо, это связано не с самой оптимальной реализацией кода.\n",
        "\n",
        "3) Графики смотрите выше.\n",
        "\n",
        "4) С задачей лучше всего справились аналитическое решение и классический градиентный спуск. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYmzzJVV54zT"
      },
      "source": [
        "## Задание 7 (2 балла).\n",
        "\n",
        "* **(1 балл)**. Добавьте в функцию из задания 5 L2-регуляризацию и, соответственно, новый аргумент - коэффициент при регуляризаторе.\n",
        "\n",
        "* **(1 балл)**. На сгенерированных выше данных обучите модифицированный алгоритм SGD с регуляризацией: в цикле перебирайте значения коэффициента регуляризации от 0.1 до 1 с шагом 0.1. Для каждого значения обучите модель и сделайте предсказание, выведите значение r2. Для какого значения коэффициента регуляризации получилось наилучшее качество r2, почему? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "b_hC1Ehi612d"
      },
      "outputs": [],
      "source": [
        "def sgd_l2(X, y, learning_rate, iterations, l2):\n",
        "    # добавляем столбец из единиц\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    # случайные веса\n",
        "    params = np.random.rand(X.shape[1])\n",
        "    # массив для лоссов \n",
        "    cost_track = np.zeros((iterations, 1))\n",
        "    for i in range(iterations):\n",
        "      # рандомное наблюдение\n",
        "      random_idx = np.random.randint(len(X - 1))\n",
        "      x = X[random_idx]\n",
        "      y_current = y[random_idx]\n",
        "      error = x @ params - y_current\n",
        "      # обновление весов\n",
        "      params_0 = params - learning_rate * (x * error)\n",
        "      Lw = x * error + l2 * params\n",
        "      params_1 = params - learning_rate  * Lw\n",
        "      params = np.hstack((params_0[0], params_1[1:]))\n",
        "      # добавляем лосс в список\n",
        "      cost_track[i] = compute_cost(X, y, params)\n",
        "    \n",
        "    return cost_track, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "TxykxLLtE9UV"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for l2 in np.linspace(0.1, 1, 10):\n",
        "  sgd_l2_track, sgd_l2_weights = sgd_l2(X, y, 0.01, 10000, l2)\n",
        "  score = r2_score(y, predict(X, sgd_l2_weights))\n",
        "\n",
        "  scores.append(score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbFOOq3bbhS4",
        "outputId": "f0001a6c-c484-427a-eb97-85fd9eb388ae"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7391345605244131,\n",
              " 0.7325797384239254,\n",
              " 0.7206985027173537,\n",
              " 0.7191910994586257,\n",
              " 0.7065160129150756,\n",
              " 0.641492194646716,\n",
              " 0.6832149900659188,\n",
              " 0.6444914291903547,\n",
              " 0.6524087030989689,\n",
              " 0.6123032094460792]"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наивысшая метрика при наименьшем коэффициенте регуляризации, и с каждым его увеличением, метрика постепенно падает, это связано с тем, что на каждой итерации веса занижаются все ниже и ниже и к какому-то моменту они оказываются черезмерно занижеными, что ведет уже к **недообучению**."
      ],
      "metadata": {
        "id": "Z3lvHuS0ljSi"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}